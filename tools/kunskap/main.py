# Copyright 2018 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Function called by PubSub trigger to execute  cron jon tasks."""
import config
import datetime
from google.cloud import bigquery
from google.cloud import datastore

bq_client = bigquery.Client()
datastore_client = datastore.Client()

# # EDIT THESE WITH YOUR OWN DATASET/TABLES
# dataset_id = 'billing_dataset'
# billing_table_name = 'billing_data'
# output_table_name = 'transformed_table'


def store_query_timestamp(current_time):
  """Creates a datastore entity object to record current time.

  Args:
      current_time: datetime object representing current time

  """
  time_as_string = current_time.strftime('%Y-%m-%d %H:%M:%S')
  key = datastore_client.key('QueryData', time_as_string)
  date_entity = datastore.Entity(key=key)
  date_entity.update({
      'time_queried': time_as_string
  })
  datastore_client.put(date_entity)


def get_last_query_time():
  """Creates query to datastore to fetch the last time a query was executed.

  Returns:
    String representing UTC-time or None
  """
  date_query = datastore_client.query(kind='QueryData')
  date_query.order = ['-time_queried']
  query_results = list(date_query.fetch())
  if query_results:
    return query_results[0]['time_queried']
  else:
    return None


def get_usage_dates(partition_ids):
  """Queries for each usage date that is stored within a partition.

  Args:
    partition_ids: List of timestamp strings denoting partition ingestion times.

  Returns:
     List of dates
  """
  job_config = bigquery.QueryJobConfig()
  sql = (
    'SELECT distinct(TIMESTAMP_TRUNC(usage_start_time, DAY, "UTC")) AS usage_date, _PARTITIONTIME as pt '
    'FROM `' + config.dataset_id + '.' + config.billing_table_name + '` '
    'WHERE _PARTITIONTIME IN ("' + '","'.join(partition_ids) + '") '
    'GROUP BY pt, usage_start_time;'
  )
  query_job = bq_client.query(sql, job_config=job_config)
  date_list = []
  for row in query_job.result():
    date_list.append(row.usage_date)
  return date_list


def get_changed_partitions():
  """Queries bigquery table to return partitions that have been updated.

  Returns:
    List of timestamp strings representing partition ids
  """
  last_query_time = get_last_query_time()
  job_config = bigquery.QueryJobConfig()
  # Obtaining partitions metadeta via the client API requires legacy SQL
  job_config.use_legacy_sql = True

  if last_query_time:
    table_name = config.dataset_id + '.' + config.billing_table_name + '$__PARTITIONS_SUMMARY__'

    sql = (
        'SELECT TIMESTAMP(partition_id) AS partition_timestamp '
        'FROM [' + table_name + '] '
        'WHERE FORMAT_UTC_USEC(last_modified_time * 1000) > "' + last_query_time + '";'
    )

    query_job = bq_client.query(sql, job_config=job_config)
    updated_partitions = []
    for row in query_job.result():
      updated_partitions.append(row.partition_timestamp.strftime('%Y-%m-%d %H:%M:%S'))
    return updated_partitions
  else:
    return None


def execute_transformation_query(dates_to_update):
  """Executes transformation query to a new destination table.

  Args:
    dates_to_update: List of strings representing dates
  """
  # Set the destination table
  table_name = bq_client.project + '.' + config.dataset_id + '.' + config.output_table_name
  table_list = [table.full_table_id for table in list(bq_client.list_tables(dataset_id))]
  if table_name in table_list:
    table_ref = bq_client.dataset(config.dataset_id).table(config.output_table_name)
  else:
    table = bq_client.dataset(config.dataset_id).table(config.output_table_name)
    table.partitioning_type = 'DAY'
    table_ref = table

  job_config = bigquery.QueryJobConfig()
  job_config.destination = table_ref
  job_config.time_partitioning = bigquery.TimePartitioning(type_='DAY')

  sql = (
      'SELECT * '
      'FROM `' + config.dataset_id + '.' + config.billing_table_name + '` '
  )

  # TO-DO: SQL to be generated by Arif
  query_job = bq_client.query(
      sql,
      job_config=job_config)

  query_job.result()  # Waits for the query to finish


def main(data, context):
  """Triggered from a message on a Cloud Pub/Sub topic.

  Args:
    data (dict): Event payload.
    context (google.cloud.functions.Context): Metadata for the event.
  """
  try:
    current_time = datetime.datetime.utcnow()
    partitions_to_update = get_changed_partitions()

    # Verify that partitions have changed/require transformation
    if partitions_to_update:
      dates_to_update = get_usage_dates(partitions_to_update)
      execute_transformation_query(dates_to_update)
      store_query_timestamp(current_time)

  except Exception as e:
    print(e)

if __name__ == '__main__':
  main('data', 'context')
